{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# To process embeddings\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# To create sentence clusters\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# To load saved embeddings\n",
    "import joblib\n",
    "\n",
    "# To match strings\n",
    "import re\n",
    "\n",
    "# To sort final recommendation list\n",
    "from collections import Counter\n",
    "\n",
    "def dataLoader(datapath, books_file, reviews_file, reviewsAll_file):\n",
    "    '''\n",
    "    Loads DataFrames with books and review information\n",
    "    '''\n",
    "    books = pd.read_csv(datapath + books_file).drop('Unnamed: 0', axis=1).fillna('')\n",
    "    reviews = pd.read_csv(datapath + reviews_file).drop('Unnamed: 0', axis=1)\n",
    "    reviewsAll = pd.read_csv(datapath + reviewsAll_file).drop('Unnamed: 0', axis=1)\n",
    "    return books, reviews, reviewsAll\n",
    "\n",
    "def loadEmbeddings():\n",
    "    '''\n",
    "    Loads pre-trained sentence and review arrays\n",
    "    '''\n",
    "    # Path to USE\n",
    "    embed = hub.load('/media/einhard/Seagate Expansion Drive/3380_data/data/tensorflow_hub/universal-sentence-encoder_4')\n",
    "\n",
    "    # Load pre-trained sentence arrays\n",
    "    ## Reviews array is a set of embeddings trained on review lengths of < 90 characters\n",
    "    reviews_array = joblib.load('/media/einhard/Seagate Expansion Drive/3380_data/data/Models/reviewEmbeddings.pkl')\n",
    "    ## Descriptions array is a set of embeddings trained on all book descriptions\n",
    "    descriptions_array = joblib.load('/media/einhard/Seagate Expansion Drive/3380_data/data/Models/descriptionEmbeddings.pkl')\n",
    "\n",
    "    return embed, reviews_array, descriptions_array\n",
    "\n",
    "def embedInputs(books_df, review_df, search_param, review_max_len, searchTitle=True):\n",
    "    '''\n",
    "    Converts input reviews into USE arrays. Returns vectorized reviews for the book that was\n",
    "    passed as bookTitle.\n",
    "\n",
    "    Args:\n",
    "        search_param = List of book titles or author names whose reviews we want to embed. For authors, see 'searchTitle' argument\n",
    "        books_df = DataFrame with book_id information\n",
    "        review_df = DataFrame with book_id and review text\n",
    "        searchTitle = If True, will search for book_id based on title of a book. If False, it will look for author names to find book_id.\n",
    "    '''\n",
    "    if searchTitle:\n",
    "        #Finds book_id from title of book\n",
    "        input_book_id = books_df[books_df.title.isin([search_param])].book_id.tolist()\n",
    "    else:\n",
    "        # Finds book_id from author name\n",
    "        input_book_id = books_df[books_df.name.isin([search_param])].book_id.tolist()\n",
    "\n",
    "    # Finds reviews for specified book\n",
    "    input_sentences = review_df[review_df.book_id.isin(input_book_id)].review_text\n",
    "\n",
    "    # Filters review length\n",
    "    input_sentences = input_sentences[input_sentences.str.len() <= review_max_len]\n",
    "\n",
    "    # Converts reviews into 512-dimensional arrays\n",
    "    input_vectors = embed(input_sentences)\n",
    "\n",
    "    # Returns reviews and vectorized reviews for a particular book\n",
    "    return input_sentences, input_vectors\n",
    "\n",
    "def getClusters(input_vectors, n_clusters):\n",
    "    '''\n",
    "    Creates KMeans instance and fits model.\n",
    "\n",
    "    The for nested for loop is used to display the returned sentences on Streamlit.\n",
    "\n",
    "    Args:\n",
    "        input_sentences =  Sentences to compare\n",
    "        n_clusters = How many clusters to generate\n",
    "    '''\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=50, algorithm='full')\n",
    "    return kmeans.fit(input_vectors)\n",
    "\n",
    "\n",
    "def showClusters(input_sentences, input_vectors, authorTitle, n_clusters, n_results, model, searchTitle=True):\n",
    "    '''\n",
    "    This function will find theme clusters in the reviews of a particular book or set of sentences.\n",
    "    Uses cluster centers to find semantically similar sentences to the input vectors.\n",
    "\n",
    "    The nested for loop is used to display the returned sentences on Streamlit.\n",
    "\n",
    "    Args:\n",
    "        input_sentences =  Sentences to compare\n",
    "        input_vectors = USE Array generated by embedding input sentences\n",
    "        authorTitle = Title of book in question, or name of author --> Used to display header only\n",
    "        n_clusters = How many clusters to generate\n",
    "        n_results = How many sentences to display per n_cluster\n",
    "        model = The model used to create the clusters.\n",
    "    '''\n",
    "    if searchTitle:\n",
    "        # Displays which book's reviews are being clustered\n",
    "        print(f'Opinion clusters about *{authorTitle}*')\n",
    "    else:\n",
    "        print(f'Opinion clusters about {authorTitle}\\'s books')\n",
    "\n",
    "    # Iterates through centroids to and computes inner products to find nlargest\n",
    "    for i in range(n_clusters):\n",
    "        centre = model.cluster_centers_[i]\n",
    "        inner_product = np.inner(centre, input_vectors)\n",
    "        indices = pd.Series(inner_product).nlargest(n_results).index\n",
    "        clusteredInputs = list(input_sentences.iloc[indices])\n",
    "\n",
    "        # Prints reviews that are closest to centroid\n",
    "    \n",
    "        print(f'**Cluster #{i+1}**')\n",
    "        for sentence in clusteredInputs:\n",
    "            print(sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to books and reviews DataFrames\n",
    "datapath = '/media/einhard/Seagate Expansion Drive/3380_data/data/Filtered books/'\n",
    "#books_file = 'clean_filtered_books.csv'\n",
    "#reviews_file = 'clean_filtered_reviews.csv'\n",
    "#reviewsAll_file = 'reviews_for_cluster.csv'#\n",
    "\n",
    "## Loading DataFrames\n",
    "#books, reviews, reviewsAll = dataLoader(datapath, books_file, reviews_file, reviewsAll_file)\n",
    "\n",
    "# Loadding pre-trained embeddings and embedder for input sentences\n",
    "embed, reviews_array, descriptions_array = loadEmbeddings()"
   ]
  },
  {
   "source": [
    "# Tokenizing reviews into sentences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   title  \\\n",
       "0                           Poet Of The Wrong Generation   \n",
       "1         Words of Radiance (The Stormlight Archive, #2)   \n",
       "2                               Mark of the Lion Trilogy   \n",
       "3      The Jesus Storybook Bible: Every Story Whisper...   \n",
       "4               Lodestar (Keeper of the Lost Cities, #5)   \n",
       "...                                                  ...   \n",
       "12357                                 The Birthing House   \n",
       "12358                       One Night at the Call Center   \n",
       "12359  Cleaving: A Story of Marriage, Meat, and Obses...   \n",
       "12360                                       Citizen Girl   \n",
       "12361    The Juliette Society (The Juliette Society, #1)   \n",
       "\n",
       "                                             description   book_id  \\\n",
       "0      \"It's not that I don't love you, and my tears ...  31675691   \n",
       "1      From #1 New York Times bestselling author Bran...  17332218   \n",
       "2                                                            95602   \n",
       "3      The Moonbeam Award Gold Medal Winner in the re...    165068   \n",
       "4      Dark schemes unfold--and Sophie's loyalty is p...  27272698   \n",
       "...                                                  ...       ...   \n",
       "12357                                                      6017367   \n",
       "12358  Press 1 for technical support.\\nPress 2 for br...    105578   \n",
       "12359  Julie Powell thought cooking her way through J...   6072179   \n",
       "12360  Another biting satire from Emma McLaughlin and...     33993   \n",
       "12361  Avant que nous allions plus loin, mettons les ...  17819467   \n",
       "\n",
       "       weighted_score                name  \n",
       "0            4.805233       Lonnie Ostrow  \n",
       "1            4.769454   Brandon Sanderson  \n",
       "2            4.755426     Francine Rivers  \n",
       "3            4.743188   Sally Lloyd-Jones  \n",
       "4            4.742152   Shannon Messenger  \n",
       "...               ...                 ...  \n",
       "12357        2.476325  Christopher Ransom  \n",
       "12358        2.471741       Chetan Bhagat  \n",
       "12359        2.440292        Julie Powell  \n",
       "12360        2.404365     Emma McLaughlin  \n",
       "12361        2.351404          Sasha Grey  \n",
       "\n",
       "[12362 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>description</th>\n      <th>book_id</th>\n      <th>weighted_score</th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Poet Of The Wrong Generation</td>\n      <td>\"It's not that I don't love you, and my tears ...</td>\n      <td>31675691</td>\n      <td>4.805233</td>\n      <td>Lonnie Ostrow</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Words of Radiance (The Stormlight Archive, #2)</td>\n      <td>From #1 New York Times bestselling author Bran...</td>\n      <td>17332218</td>\n      <td>4.769454</td>\n      <td>Brandon Sanderson</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mark of the Lion Trilogy</td>\n      <td></td>\n      <td>95602</td>\n      <td>4.755426</td>\n      <td>Francine Rivers</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The Jesus Storybook Bible: Every Story Whisper...</td>\n      <td>The Moonbeam Award Gold Medal Winner in the re...</td>\n      <td>165068</td>\n      <td>4.743188</td>\n      <td>Sally Lloyd-Jones</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lodestar (Keeper of the Lost Cities, #5)</td>\n      <td>Dark schemes unfold--and Sophie's loyalty is p...</td>\n      <td>27272698</td>\n      <td>4.742152</td>\n      <td>Shannon Messenger</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12357</th>\n      <td>The Birthing House</td>\n      <td></td>\n      <td>6017367</td>\n      <td>2.476325</td>\n      <td>Christopher Ransom</td>\n    </tr>\n    <tr>\n      <th>12358</th>\n      <td>One Night at the Call Center</td>\n      <td>Press 1 for technical support.\\nPress 2 for br...</td>\n      <td>105578</td>\n      <td>2.471741</td>\n      <td>Chetan Bhagat</td>\n    </tr>\n    <tr>\n      <th>12359</th>\n      <td>Cleaving: A Story of Marriage, Meat, and Obses...</td>\n      <td>Julie Powell thought cooking her way through J...</td>\n      <td>6072179</td>\n      <td>2.440292</td>\n      <td>Julie Powell</td>\n    </tr>\n    <tr>\n      <th>12360</th>\n      <td>Citizen Girl</td>\n      <td>Another biting satire from Emma McLaughlin and...</td>\n      <td>33993</td>\n      <td>2.404365</td>\n      <td>Emma McLaughlin</td>\n    </tr>\n    <tr>\n      <th>12361</th>\n      <td>The Juliette Society (The Juliette Society, #1)</td>\n      <td>Avant que nous allions plus loin, mettons les ...</td>\n      <td>17819467</td>\n      <td>2.351404</td>\n      <td>Sasha Grey</td>\n    </tr>\n  </tbody>\n</table>\n<p>12362 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "booksdescription\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentences(reviews_df):\n",
    "    '''\n",
    "    Copyright (c) 2020 Willie Costello\n",
    "    '''\n",
    "    # Initialize dataframe to store review sentences, and counter\n",
    "    sentences_df = pd.DataFrame()\n",
    "    ctr = 0\n",
    "\n",
    "    print(f'Starting tokenization')\n",
    "\n",
    "    # Loop through each review\n",
    "    for i in range(len(reviews_df)):\n",
    "\n",
    "        # Save row and review to variables\n",
    "        row = reviews_df.iloc[i]\n",
    "        review = row.loc['description']\n",
    "\n",
    "        # Tokenize review into sentences\n",
    "        sentences = sent_tokenize(review)\n",
    "\n",
    "        # Loop through each sentence in list of tokenized sentences\n",
    "        for sentence in sentences:\n",
    "            # Add row for sentence to sentences dataframe\n",
    "            new_row = row.copy()\n",
    "            new_row.at['description'] = sentence\n",
    "            sentences_df = sentences_df.append(new_row, ignore_index=True)\n",
    "\n",
    "        ctr += 1\n",
    "        if (ctr % 500 == 0):\n",
    "            print(f'{ctr} reviews tokenized')\n",
    "\n",
    "    print(f'Tokenization complete: {len(sentences_df)} sentences tokenized\\n')\n",
    "\n",
    "    # Rename review column\n",
    "    sentences_df.rename(columns={'description':'description_tokenized'}, inplace=True)\n",
    "\n",
    "    return sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting tokenization\n",
      "500 reviews tokenized\n",
      "1000 reviews tokenized\n",
      "1500 reviews tokenized\n",
      "2000 reviews tokenized\n",
      "2500 reviews tokenized\n",
      "3000 reviews tokenized\n",
      "3500 reviews tokenized\n",
      "4000 reviews tokenized\n",
      "4500 reviews tokenized\n",
      "5000 reviews tokenized\n",
      "5500 reviews tokenized\n",
      "6000 reviews tokenized\n",
      "6500 reviews tokenized\n",
      "7000 reviews tokenized\n",
      "7500 reviews tokenized\n",
      "8000 reviews tokenized\n",
      "8500 reviews tokenized\n",
      "9000 reviews tokenized\n",
      "9500 reviews tokenized\n",
      "10000 reviews tokenized\n",
      "10500 reviews tokenized\n",
      "11000 reviews tokenized\n",
      "11500 reviews tokenized\n",
      "12000 reviews tokenized\n",
      "Tokenization complete: 105923 sentences tokenized\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descriptionsTokenized = make_sentences(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptionsTokenized.to_csv('/media/einhard/Seagate Expansion Drive/3380_data/data/tokenized sentences/descriptionsTokenized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "descriptionsTokenized = pd.read_csv('/media/einhard/Seagate Expansion Drive/3380_data/data/tokenized sentences/descriptionsTokenized.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           book_id                              description_tokenized  \\\n",
       "0       31675691.0  \"It's not that I don't love you, and my tears ...   \n",
       "1       31675691.0  But you can't go back and forth forever and we...   \n",
       "2       31675691.0  Through these words, a young poet unearths his...   \n",
       "3       31675691.0  Unknowingly, in writing this ballad of liberat...   \n",
       "4       31675691.0        The year is 1991; the place, New York City.   \n",
       "...            ...                                                ...   \n",
       "105917  17819467.0  OK. A present, passons aux choses serieuses.Sa...   \n",
       "105918  17819467.0  Apres avoir quitte l'univers des films pour ad...   \n",
       "105919  17819467.0             Juliette Societyest son premier roman.   \n",
       "105920  17819467.0           Un feminisme moderne pousse a l'extreme.   \n",
       "105921  17819467.0                     Elle UK Un Fight Club feminin.   \n",
       "\n",
       "                 name                                            title  \\\n",
       "0       Lonnie Ostrow                     Poet Of The Wrong Generation   \n",
       "1       Lonnie Ostrow                     Poet Of The Wrong Generation   \n",
       "2       Lonnie Ostrow                     Poet Of The Wrong Generation   \n",
       "3       Lonnie Ostrow                     Poet Of The Wrong Generation   \n",
       "4       Lonnie Ostrow                     Poet Of The Wrong Generation   \n",
       "...               ...                                              ...   \n",
       "105917     Sasha Grey  The Juliette Society (The Juliette Society, #1)   \n",
       "105918     Sasha Grey  The Juliette Society (The Juliette Society, #1)   \n",
       "105919     Sasha Grey  The Juliette Society (The Juliette Society, #1)   \n",
       "105920     Sasha Grey  The Juliette Society (The Juliette Society, #1)   \n",
       "105921     Sasha Grey  The Juliette Society (The Juliette Society, #1)   \n",
       "\n",
       "        weighted_score  \n",
       "0             4.805233  \n",
       "1             4.805233  \n",
       "2             4.805233  \n",
       "3             4.805233  \n",
       "4             4.805233  \n",
       "...                ...  \n",
       "105917        2.351404  \n",
       "105918        2.351404  \n",
       "105919        2.351404  \n",
       "105920        2.351404  \n",
       "105921        2.351404  \n",
       "\n",
       "[101184 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>book_id</th>\n      <th>description_tokenized</th>\n      <th>name</th>\n      <th>title</th>\n      <th>weighted_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31675691.0</td>\n      <td>\"It's not that I don't love you, and my tears ...</td>\n      <td>Lonnie Ostrow</td>\n      <td>Poet Of The Wrong Generation</td>\n      <td>4.805233</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>31675691.0</td>\n      <td>But you can't go back and forth forever and we...</td>\n      <td>Lonnie Ostrow</td>\n      <td>Poet Of The Wrong Generation</td>\n      <td>4.805233</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31675691.0</td>\n      <td>Through these words, a young poet unearths his...</td>\n      <td>Lonnie Ostrow</td>\n      <td>Poet Of The Wrong Generation</td>\n      <td>4.805233</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31675691.0</td>\n      <td>Unknowingly, in writing this ballad of liberat...</td>\n      <td>Lonnie Ostrow</td>\n      <td>Poet Of The Wrong Generation</td>\n      <td>4.805233</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>31675691.0</td>\n      <td>The year is 1991; the place, New York City.</td>\n      <td>Lonnie Ostrow</td>\n      <td>Poet Of The Wrong Generation</td>\n      <td>4.805233</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>105917</th>\n      <td>17819467.0</td>\n      <td>OK. A present, passons aux choses serieuses.Sa...</td>\n      <td>Sasha Grey</td>\n      <td>The Juliette Society (The Juliette Society, #1)</td>\n      <td>2.351404</td>\n    </tr>\n    <tr>\n      <th>105918</th>\n      <td>17819467.0</td>\n      <td>Apres avoir quitte l'univers des films pour ad...</td>\n      <td>Sasha Grey</td>\n      <td>The Juliette Society (The Juliette Society, #1)</td>\n      <td>2.351404</td>\n    </tr>\n    <tr>\n      <th>105919</th>\n      <td>17819467.0</td>\n      <td>Juliette Societyest son premier roman.</td>\n      <td>Sasha Grey</td>\n      <td>The Juliette Society (The Juliette Society, #1)</td>\n      <td>2.351404</td>\n    </tr>\n    <tr>\n      <th>105920</th>\n      <td>17819467.0</td>\n      <td>Un feminisme moderne pousse a l'extreme.</td>\n      <td>Sasha Grey</td>\n      <td>The Juliette Society (The Juliette Society, #1)</td>\n      <td>2.351404</td>\n    </tr>\n    <tr>\n      <th>105921</th>\n      <td>17819467.0</td>\n      <td>Elle UK Un Fight Club feminin.</td>\n      <td>Sasha Grey</td>\n      <td>The Juliette Society (The Juliette Society, #1)</td>\n      <td>2.351404</td>\n    </tr>\n  </tbody>\n</table>\n<p>101184 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "descriptionsTokenized[(descriptionsTokenized.description_tokenized.str.len() > 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = embed(['Poet of the Wrong Generation tells the symmetrical story of a lovable underdog and his meteoric rise to stardom, his humiliating downfall and his unprecedented attempt to reclaim his place as the unlikely musical spokesman for his generation.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embed = embed(descriptionsTokenized[:20].description_tokenized.reset_index().drop('index', axis=1).description_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_product = descriptionsTokenized[:20].description_tokenized.reset_index().drop('index', axis=1).description_tokenized.apply(lambda row: np.inner(test_embed, input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          0\n",
       "0  0.990335"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.990335</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "source": [
    "pd.DataFrame(inner_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Int64Index([0], dtype='int64')"
      ]
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "source": [
    "pd.DataFrame(inner_product).nlargest(5, columns=0).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.DataFrame(inner_product).nlargest(5, columns=0).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    \"It's not that I don't love you, and my tears ...\n",
       "Name: description_tokenized, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "descriptionsTokenized.description_tokenized[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Through these words, a young poet unearths his musical soul while severing ties with the woman he loves after her stunning betrayal.',\n",
       " 'Expected by his enemies to die the miserable death of a military slave, Kaladin survived to be given command of the royal bodyguards, a controversial first for a low-status \"darkeyes.\"',\n",
       " 'From Noah to Moses to the great King David--every story points to him.',\n",
       " 'The year is 1991; the place, New York City.',\n",
       " 'At the heart of Poet is a tale of star-crossed lovers and their struggle with unforeseen success and disillusionment, in an attempt to rediscover lasting harmony.']"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "descriptionsTokenized.description_tokenized[indices].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20    The secrets she needs can be found at the Shat...\n",
       "21    Meanwhile, at the heart of the Shattered Plain...\n",
       "22    Hard pressed by years of Alethi attacks, their...\n",
       "23    The possible consequences for Parshendi and hu...\n",
       "24    The Moonbeam Award Gold Medal Winner in the re...\n",
       "25    At the center of the Story is a baby, the chil...\n",
       "26                       Every story whispers his name.\n",
       "27    From Noah to Moses to the great King David--ev...\n",
       "28    He is like the missing piece in a puzzle--the ...\n",
       "29    From the Old Testament through the New Testame...\n",
       "30    A Bible like no other, The Jesus Storybook Bib...\n",
       "31    Dark schemes unfold--and Sophie's loyalty is p...\n",
       "32    Sophie Foster is back in the Lost Cities--but ...\n",
       "33    The threat of war hangs heavy over her glitter...\n",
       "34    The lines between friend and enemy have blurre...\n",
       "35    But when she's warned that the people she love...\n",
       "36    A mysterious symbol could be the key--if only ...\n",
       "37    Every new clue seems to lead deeper into her w...\n",
       "38    The Neverseen have their own Initiative, and i...\n",
       "39    The exciting tales of Harry Potter, the young ...\n",
       "40    If you buy one of the Harry Potter books, we g...\n",
       "41    With the Harry Potter Boxed Set (Years 1-7), B...\n",
       "42    As easy as the wave of a magic wand, you can g...\n",
       "43    The Harry Potter Boxed Set includes hardcover ...\n",
       "44    So buy the set, and not even a pesky Locomotor...\n",
       "45      Hold on tight -- it's going to be a bumpy ride!\n",
       "46          A collection of Calvin and Hobbes cartoons.\n",
       "47    The author won the 1986 Reuben Award as Outsta...\n",
       "48                     and Weirdos From Another Planet.\n",
       "49    Feyre survived Amarantha's clutches to return ...\n",
       "Name: description_tokenized, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "descriptionsTokenized[20:50].description_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0     The secrets she needs can be found at the Shat...\n",
       "1     Meanwhile, at the heart of the Shattered Plain...\n",
       "2     Hard pressed by years of Alethi attacks, their...\n",
       "3     The possible consequences for Parshendi and hu...\n",
       "4     The Moonbeam Award Gold Medal Winner in the re...\n",
       "5     At the center of the Story is a baby, the chil...\n",
       "6                        Every story whispers his name.\n",
       "7     From Noah to Moses to the great King David--ev...\n",
       "8     He is like the missing piece in a puzzle--the ...\n",
       "9     From the Old Testament through the New Testame...\n",
       "10    A Bible like no other, The Jesus Storybook Bib...\n",
       "11    Dark schemes unfold--and Sophie's loyalty is p...\n",
       "12    Sophie Foster is back in the Lost Cities--but ...\n",
       "13    The threat of war hangs heavy over her glitter...\n",
       "14    The lines between friend and enemy have blurre...\n",
       "15    But when she's warned that the people she love...\n",
       "16    A mysterious symbol could be the key--if only ...\n",
       "17    Every new clue seems to lead deeper into her w...\n",
       "18    The Neverseen have their own Initiative, and i...\n",
       "19    The exciting tales of Harry Potter, the young ...\n",
       "20    If you buy one of the Harry Potter books, we g...\n",
       "21    With the Harry Potter Boxed Set (Years 1-7), B...\n",
       "22    As easy as the wave of a magic wand, you can g...\n",
       "23    The Harry Potter Boxed Set includes hardcover ...\n",
       "24    So buy the set, and not even a pesky Locomotor...\n",
       "25      Hold on tight -- it's going to be a bumpy ride!\n",
       "26          A collection of Calvin and Hobbes cartoons.\n",
       "27    The author won the 1986 Reuben Award as Outsta...\n",
       "28                     and Weirdos From Another Planet.\n",
       "29    Feyre survived Amarantha's clutches to return ...\n",
       "Name: description_tokenized, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "descriptionsTokenized[20:50].description_tokenized.reset_index().drop('index', axis=1).description_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20    The secrets she needs can be found at the Shat...\n",
       "21    Meanwhile, at the heart of the Shattered Plain...\n",
       "22    Hard pressed by years of Alethi attacks, their...\n",
       "23    The possible consequences for Parshendi and hu...\n",
       "24    The Moonbeam Award Gold Medal Winner in the re...\n",
       "25    At the center of the Story is a baby, the chil...\n",
       "26                       Every story whispers his name.\n",
       "27    From Noah to Moses to the great King David--ev...\n",
       "28    He is like the missing piece in a puzzle--the ...\n",
       "29    From the Old Testament through the New Testame...\n",
       "30    A Bible like no other, The Jesus Storybook Bib...\n",
       "31    Dark schemes unfold--and Sophie's loyalty is p...\n",
       "32    Sophie Foster is back in the Lost Cities--but ...\n",
       "33    The threat of war hangs heavy over her glitter...\n",
       "34    The lines between friend and enemy have blurre...\n",
       "35    But when she's warned that the people she love...\n",
       "36    A mysterious symbol could be the key--if only ...\n",
       "37    Every new clue seems to lead deeper into her w...\n",
       "38    The Neverseen have their own Initiative, and i...\n",
       "39    The exciting tales of Harry Potter, the young ...\n",
       "40    If you buy one of the Harry Potter books, we g...\n",
       "41    With the Harry Potter Boxed Set (Years 1-7), B...\n",
       "42    As easy as the wave of a magic wand, you can g...\n",
       "43    The Harry Potter Boxed Set includes hardcover ...\n",
       "44    So buy the set, and not even a pesky Locomotor...\n",
       "45      Hold on tight -- it's going to be a bumpy ride!\n",
       "46          A collection of Calvin and Hobbes cartoons.\n",
       "47    The author won the 1986 Reuben Award as Outsta...\n",
       "48                     and Weirdos From Another Planet.\n",
       "49    Feyre survived Amarantha's clutches to return ...\n",
       "Name: description_tokenized, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "descriptionsTokenized[20:50].description_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptionsTokenized['embedded'] = descriptionsTokenized['description_tokenized'].apply(lambda row: embed([row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = embed(['Through these words, a young poet unearths his musical soul while severing ties with the woman he loves after her stunning betrayal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-1477af871692>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptionsTokenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6929\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6930\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6931\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6932\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                                                   stack(strides))\n\u001b[1;32m   1001\u001b[0m       if (packed_begin.dtype == dtypes.int64 or\n\u001b[0;32m-> 1002\u001b[0;31m           \u001b[0mpacked_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m           packed_strides.dtype == dtypes.int64):\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpacked_begin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_enum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_enum\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__ne__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = np.inner(descriptionsTokenized.embedded.tolist(), input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-64c5cdee15af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptionsTokenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   6928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6929\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6930\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6931\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6932\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    998\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n\u001b[0;32m-> 1000\u001b[0;31m                                                   stack(strides))\n\u001b[0m\u001b[1;32m   1001\u001b[0m       if (packed_begin.dtype == dtypes.int64 or\n\u001b[1;32m   1002\u001b[0m           \u001b[0mpacked_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1379\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Input list contains non-constant tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.asarray(descriptionsTokenized.embedded.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "execution_count": 185
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = pd.Series(test.reshape(len(test))).nlargest(5).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[2, 10, 3, 5, 8]"
      ]
     },
     "metadata": {},
     "execution_count": 189
    }
   ],
   "source": [
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Through these words, a young poet unearths his musical soul while severing ties with the woman he loves after her stunning betrayal.',\n",
       " 'At the heart of Poet is a tale of star-crossed lovers and their struggle with unforeseen success and disillusionment, in an attempt to rediscover lasting harmony.',\n",
       " 'Unknowingly, in writing this ballad of liberation, he will soon evolve as one of the fastest rising stars on the pop music landscape.',\n",
       " 'Here we meet Johnny Elias, a college student from Brooklyn with boundless adoration for two things in life: timeless popular music, and the heart of a sweet, complicated young woman who is clearly out of his league.',\n",
       " 'But in her callous disregard, she inadvertently sets him on a determined course to his improbable musical destiny - while sending her own daughter spiraling down a path of devastation.']"
      ]
     },
     "metadata": {},
     "execution_count": 190
    }
   ],
   "source": [
    "descriptionsTokenized.description_tokenized[test_index].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}